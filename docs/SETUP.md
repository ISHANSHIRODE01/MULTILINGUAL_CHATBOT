# Setup Guide\n\n## Prerequisites\n\n- Python 3.8+\n- Windows/Linux/macOS\n- 4GB RAM minimum\n- Internet connection (for model downloads)\n\n## Installation\n\n### 1. Clone Repository\n```bash\ngit clone <repository-url>\ncd multilingual-chatbot\n```\n\n### 2. Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n### 3. Configure Environment\n\n**Optional: Add Gemini API Key**\n1. Get API key from [Google AI Studio](https://makersuite.google.com/app/apikey)\n2. Create `.env` file:\n   ```\n   GEMINI_API_KEY=your_api_key_here\n   ```\n\n### 4. Create Directories\n```bash\nmkdir temp uploads logs\n```\n\n## Running the Application\n\n### Method 1: Manual Start\n\n**Terminal 1 - Backend:**\n```bash\npython src/backend/app.py\n```\n\n**Terminal 2 - Frontend:**\n```bash\nstreamlit run src/frontend/streamlit_app.py\n```\n\n### Method 2: Using Scripts\n\n**Windows:**\n```batch\n# Create start.bat\n@echo off\nstart \"Backend\" cmd /k \"python src/backend/app.py\"\ntimeout /t 3 /nobreak > nul\nstart \"Frontend\" cmd /k \"streamlit run src/frontend/streamlit_app.py\"\n```\n\n**Linux/macOS:**\n```bash\n# Create start.sh\n#!/bin/bash\npython src/backend/app.py &\nsleep 3\nstreamlit run src/frontend/streamlit_app.py\n```\n\n## Verification\n\n1. Backend: http://localhost:8000/health\n2. Frontend: http://localhost:8501\n3. Upload test audio file\n4. Check for German response\n\n## Troubleshooting\n\n### Common Issues\n\n**Port Already in Use:**\n```bash\n# Kill processes on ports\nnetstat -ano | findstr :8000\ntaskkill /PID <process_id> /F\n```\n\n**Missing Dependencies:**\n```bash\npip install --upgrade pip\npip install -r requirements.txt --force-reinstall\n```\n\n**Model Download Issues:**\n- Ensure internet connection\n- Models download automatically on first use\n- Check available disk space (2GB+)\n\n**Audio Processing Errors:**\n- Supported formats: wav, mp3, m4a, ogg\n- Max file size: 10MB\n- Check file permissions\n\n### Performance Optimization\n\n**For Better Performance:**\n1. Use faster-whisper: `pip install faster-whisper`\n2. Use GPU if available\n3. Reduce model size in code (base â†’ tiny)\n\n**Memory Issues:**\n- Close other applications\n- Use smaller Whisper model\n- Process shorter audio files